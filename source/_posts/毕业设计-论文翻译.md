---
title: 毕业设计-论文翻译
date: 2021-02-24 16:01:49
tags:
	- 毕业设计
cover: bg.jpg
top_img: bg.jpg
mathjax: true
---

### 原文：
[Machine Learning Enabling Analog Beam Selection for Concurrent Transmissions in Millimeter-Wave V2V Communications](https://ieeexplore.ieee.org/document/9113407)

### 标题：

在毫米波 V2V 通信中实现并发传输的机器学习启用模拟波束选择

> **毫米波：**
> 毫米波移动通信存在传输距离短、穿透和绕射能力差、容易受气候环境影响等缺点。因此，打造出具有高增益、有自适应波束形成和波束控制能力的天线阵列，成为毫米波天线设计的首要任务，此外，由于毫米波的传输距离短，要达到良好的覆盖效果，必须用大量的毫米波天线实现覆盖



### 0.摘要

随着毫米波 （mmWave） 技术和车辆对车辆 （V2V） 通信的发展，预计毫米波车辆专用网络 （VANETs） 将支持快速增长的车辆数量。在此背景下，预计每个 V2V 用户 （VUE） 将采用**大规模阵列**来形成**定向模拟波束**，以改进**空间频谱重用**，并能够同时实现来自多个其他 VUE 的并发传输。但是，由于 V2V 链路的高动态性，每个 VUE 快速选择有效的模拟光束可能具有挑战性。在本文中，我们提出了一种机器学习 （ML） 方法，以实现 mmWave V2V 通信高效、快速的模拟波束选择。具体来说，我们首先推导出多个 V2V 发射器 （TX） 为一个 VUE 提供服务以获得 mmWave V2V 通信的平均总和率 （ASR）。在此基础上，我们开发了一种 ML 方法，以最大限度地提高 ASR，从而将支持矢量机 （SVM） 分类器用于优化模拟光束选择。此外，我们还提出了迭代顺序最小优化培训算法，以训练所有 V2V 链路的数据样本，并讨论了建议解决方案的趋同性。最后，使用谷歌TensorFlow对广泛的样本培训和模拟进行了评估。结果证明，我们建议的 ML 方法能够实现更高的 ASR，但计算复杂性远低于基于明确估计的渠道的传统解决方案。

**Index Tearms：**机器学习、毫米波车辆专用网络、并发传输、模拟波束选择、支持向量机

> **背景：**
> `V2X` ，即 Vehicle to Everything 
> `V2V`（虚拟机到虚拟机的迁移，Virtual to Virtual），又称虚拟机的克隆。
> `V2R`（车辆与路侧单元，vehicle to roadside unit）
> `V2I`（车与道路基础设施通信）
>
> mmWave + V2V = `VANETs`
>
> **建模：**
> 多个 V2V 发射器 （TX） 为一个 VUE 提供服务
>
> **机器学习:**
>
> 1. 实现 mmWave V2V 通信高效、快速的模拟波束选择
>    1. 推导出ASR
>    2. ML方法最大限度提高ASR
>    3. SVM分类器优化模拟波束选择
> 2. 迭代顺序最小优化培训算法
>    1. 训练所有V2V链路的数据样本
>    2. 趋同性



### 1.介绍

毫米波（mmWave）的车对车（V2V）通信在未来的车辆自组织网络（VANET）中扮演着重要的角色。 随着车辆的车载单元（OBU）不断增加，支持数千个连接以提供各种本地服务，例如高清晰度（HD）地图，自动驾驶等。 因此，对更大带宽和更高传输速率的需求触发了毫米波V2V通信的发展。 通过利用VANET中的mmWave大型阵列来提高空间频谱效率，**多个V2V用户（VUE）可以实现与同一目标VUE对齐的定向模拟波束**，以同时提供并发传输。 在此，短距离V2V通信可以大大减少mmWave传输的路径损耗

mmWave V2V通信的并发传输在先前的工作中已经作为重要问题进行了研究[3]，[4]。 这些方案基于**VUE发射机（TX）选择合适的模拟波束为目标VUE发射信号的传统方法**。 在[3]中，为了保证毫米波通信的鲁棒性，提出了**一种具有波束跟踪和自愈功能的波束管理方法**。 文献[4]通过组合预编码矩阵以最大化下行链路传输速率来扩展波束选择。 但是，这些方法通常会评估所有可能的光束，并且会花费很高的计算复杂度。 尤其是当VANET中分布有大量VUE时，使用这些传统方法来提高性能（例如系统鲁棒性[3]，频谱效率[5]等）变得越来越困难。

> **鲁棒性：**健壮和强壮的意思。它也是在异常和危险情况下系统生存的能力

幸运的是，作为最热门的人工智能（AI）技术之一，机器学习（ML）或深度学习（DL）显示了一种非常有前途的提高无线通信性能的方法[6]。**通过训练网络的历史数据，可以提取系统功能以改善通信性能**，例如智能调制[7]，智能波束管理[8]等。 借助这些AI技术，**可以有效缓解高复杂度和高延迟的问题**，这显示了非常有前途的应用前景。

因此，在本文中，我们的研究工作提出了一种新的基于ML的毫米波V2V通信中并发传输方法，其中提出了一种低复杂度和有效的模拟波束选择方法。特别是，**通过使用异构泊松点过程（HPPP）的随机分布对大量VUE建模**[9]，我们得出了并发传输下V2V通信的平均总速率（ASR）。此外，将VANET中的所有V2V链接作为用于ML训练的大型数据库进行采样，此外，针对每个VUE的模拟波束选择，提出了一个迭代的一对一（1v1）支持向量机（SVM）分类器。此外，我们设计了一种迭代顺序最小优化（SMO）训练算法，其中VUE发射机（TX）可以在并发传输期间实现高效且低复杂度的模拟波束选择。最后，Google TensorFlow用于ML训练和网络仿真。结果证明，我们提出的算法非常接近理论性能边界，同时大大降低了计算复杂度。我们还证明，与传统的基于信道估计的方法相比，我们提出的算法可以实现更高的并发传输ASR。

在本文的其余部分，第二部分介绍了mmWave V2V通信的系统模型。 第三节推导了并发传输的ASR。 在第四部分，我们分析了提出的迭代1v1 SVM分类器，并设计了SMO训练算法。 最后，在第五部分讨论了仿真结果，第六部分总结了本文。



### 2.系统模型

我们将毫米波VANET模型建模为均一的泊松点过程（HPPP）$\Pi_V$，其二维平面ℜ上的V2V链路密度为$\lambda_V$。 V2V链接是一对VUE TX和VUE RX(发射器与接收器)之间的通信链接，其中该V2V链接建立在毫米波频率[10]上。因此，V2V链接密度表示单位面积中V2V链接的平均数量。 VUE的所有OBU都支持mmWave大规模MIMO用于V2V通信，其中天线编号表示为$N_{OBU}$。借助**波束成形**技术，天线之前的每个射频（RF）链都有一系列的移相器，可以在其中形成模拟波束并将其定向到目标VUE。如图1所示，每个VUE可以形成一个定向波束以将信号传输到另一个VUE，这样多个VUE可以实现与同一目标VUE对齐的定向模拟波束，以同时提供并发传输[10]。如果由OBU执行信道估计，则可以知道每个V2V链路的CSI。根据Slivnyak的理论[9]，定义了原始VUE的典型RX，它不会影响HPPP的统计属性。将$R$表示为最大通信距离，可以将**接收器周围的平均VUE发送器**（TX）写为
$$
N_V=\lfloor\lambda_V\pi R^2\rfloor\tag{1}
$$
其中⌊.⌋是实用的 VANET 的向下取整功能。将第 $k$ 个V2V 链接数据流定义为 $d_{V,k},(1 ≤ k ≤ N_V)$，将 VUE 的第$k$个TX 功率定义为 $P_{V,k}$。**VUE TX 的信号**可以写成
$$
\mathbf{s}_{V,k}=\mathbf{c}_{V,k}d_{V,k}\tag{2}
$$
其中 $\mathbf{c}_{V,k}\in \mathbb{C}^{N_{OBU}\times1}$ 是第$k$个VUE的模拟波束，它使用相移器来定向指向接收器。毫米波通道传播基于扩展的萨利赫-瓦伦祖德拉模型 [4]，该模型定义为如下的**窄频段聚类通道模型**：
$$
\mathbf{H}_{V,k}=\gamma\sum_{l=1}^L\alpha_{V,k,l}\pmb{\alpha}_{RV}(\phi_{RV,k,l})[\pmb{\alpha}_{V,k}(\phi_{V,k,l})]^H\tag{3}
$$
其中 $\gamma=\frac{N_{OBU}}{\sqrt{L}}$，$L$ 是传播路径的数量，$\alpha_{V,k,l}$ 是第 $l$ 条路径的复杂增益，$\alpha_{V,k,l}\sim\mathcal{CN}(0,1)$。$\mathbf{H}_{V,k}$ 满足 $\|\mathbf{H}_{V,k}\|_F^2=N_{OBU}^2$，其中 $\|.\|_F$ 是矩阵的弗罗贝纽斯规范。$\pmb{\alpha}_{RV}(\phi_{RV,k,l})$ 和 $\pmb{\alpha}_{V,k}(\phi_{V,k,l})$ 分别是每个V2V链路中RX和TX的天线阵列响应。$\phi_{RV,l}$ 和 $\phi_{V,l}$ 是与RX和TX之间的第 $l$ 条路径相关的 AoA 和 AoD 的方位角。我们假设所有OBU都沿y轴部署统一线性阵列（ULA）的天线。因此，**阵列转向向量** $\pmb{\alpha}_{RV}(\phi_{RV,k,l})$ 和 $\pmb{\alpha}_{V,k}(\phi_{V,k,l})$ 可以被写作：
$$
\pmb{\alpha}_{RV}(\phi_{RV,k,l})=\frac{[1,e^{j\sigma D_{RV}\sin(\phi_{RV,k,l})},...,e^{j\sigma D_{RV}(N_{OBU}-1)\sin(\phi_{RV,k,l})}]^T}{\sqrt{N_{OBU}}}\tag{4}
$$

$$
\pmb{\alpha}_{V}(\phi_{V,k,l})=\frac{[1,e^{j\sigma D_{V}\sin(\phi_{V,k,l})},...,e^{j\sigma D_{V}(N_{OBU}-1)\sin(\phi_{V,k,l})}]^T}{\sqrt{N_{OBU}}}\tag{5}
$$

其中 $\sigma=\frac{2\pi}{\lambda}$ ，$\lambda$ 是该信号波长，$D_{RV}$ 和 $D_{V}$ 分别是RX和TX中两个相邻的ULA元素的间距。然后，**接收信号**可以被表示为：
$$
\mathbf{y}_{RV}=\mathbf{g}_{RV}\sum_{k=1}^{N_V}\mathbf{H}_{V,k}\mathbf{c}_{V,k}d_{V,k}+\mathbf{g}_{RV}\mathbf{n}\\=\mathbf{g}_{RV}[\mathbf{H}_{V,1}\mathbf{c}_{V,1},...,\mathbf{H}_{V,N_V}\mathbf{c}_{V,N_V}]\left[
\begin{matrix}d_{V,k}\\\vdots\\d_{V,N_V}\\\end{matrix}\right]+\mathbf{g}_{RV}\mathbf{n}\tag{6}
$$
其中 $\mathbf{g}_{RV}=\left[\begin{matrix}g_{RV,1}&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&g_{RV,N_{OBU}}\\\end{matrix}\right]$，此矩阵中的每个对角线元素表示接收天线的相移器值。然后**用迫零接收机(ZF)将该信号转变**为
$$
\mathbf{y}_{RV,ZF}=[d_{V,1},\cdots,d_{V,N_V}]^T+(\mathbf{G}^H\mathbf{G})^{-1}\mathbf{G}^H\mathbf{g}_{RV}\mathbf{n}
\tag{7}
$$
其中 $\mathbf{G}=\mathbf{g}_{RV}[\mathbf{H}_{V,1}\mathbf{c}_{V,1},\cdots,\mathbf{H}_{V,N_V}\mathbf{c}_{V,N_V}]$。

在V2V通信中，所有VUE发射机根据预先定义的码本选择候选矢量，形成定向模拟波束，预先定义的码本为 $\mathcal{C}=\{\mathbf{c}_V^1,\mathbf{c}_V^2,\cdots,\mathbf{c}_V^{V_C}\}$，其中 $\mathbf{c}_V^i\in \mathbb{C}^{N_{OBU}\times1},i=1,2,\cdots,N_C,(N_C\gt2)$，$N_C$ 是候选矢量的个数。



### 3.并发传输的ASR(平均总传输速率)

在文献7中，噪声功率满足
$$
E[(\mathbf{G}^H\mathbf{G})^{-1}\mathbf{G}^H\mathbf{g}_{RV}\mathbf{n}]=\delta^2(\mathbf{G}^H\mathbf{G})^{-1}
\tag{8}
$$



这里的 $$\delta^2$$ 是高斯白噪声的方差。对于第 $$k$$ 个V2V链路，其传输速率满足
$$
R_{k}=\log _{2}\left(1+\frac{P_{\mathrm{V}, k}\left\|\mathbf{H}_{\mathrm{V}, k} \mathbf{c}_{\mathrm{V}, k}\right\|^{2}}{N_{\mathrm{OBU}} \sigma^{2}}\right)
\tag{9}
$$
因为总共存在 $\tau$ 个V2V链路，所以所有的传输速率满足 
$$
R_{\tau}=\sum_{k=1}^\tau\log _{2}\left(1+\frac{P_{\mathrm{V}, k}\left\|\mathbf{H}_{\mathrm{V}, k} \mathbf{c}_{\mathrm{V}, k}\right\|^{2}}{N_{\mathrm{OBU}} \sigma^{2}}\right), \quad(\tau=1,2,3...)
\tag{10}
$$
根据HPPP(异构泊松点过程)和泊松分布，我们可以知道对于每一个 $\tau$ ，在典型RX周围r半径范围内的VUE数的概率函数为
$$
\operatorname{Pr}_{V}\left(N_{\mathrm{V}}=\tau\right)=\frac{\left(\lambda_{\mathrm{V}} \pi R^{2}\right)^{\tau}}{\tau !} e^{-\lambda \mathrm{v} \pi R^{2}}, \quad(\tau=1,2,3 \ldots)\tag{11}
$$
因此，ASR度量被定义为一个平均值，即在所有可能的 $\tau$ ( $\tau$ 从1到无穷) 下的传输速率期望，满足
$$
\text { ASR }_{\mathrm{RV}}
=\lim\limits _{\tau \rightarrow \infty} \sum_{k=1}^\tau\left[\frac{\left(\lambda_{\mathrm{V}} \pi R^{2}\right)^{\tau}}{\tau !} e^{-\lambda_{\mathrm{V}} \pi R^{2}}\right] \log _{2}\left(1+\frac{P_{\mathrm{V}, k}\left\|\mathbf{H}_{\mathrm{V}, k} \mathbf{c}_{\mathrm{V}, k}\right\|^{2}}{N_{\mathrm{OBU}} \sigma^{2}}\right)\tag{12}
$$

这里的 $\mathrm{SNR}_{\mathrm{V}, k}=P_{\mathrm{V}, k}\left\|\mathbf{H}_{\mathrm{V}, k} \mathbf{c}_{\mathrm{V}, k}\right\|^{2} /\left(N_{\mathrm{OBU}} \sigma^{2}\right)$ 是来自所有 VUE 的并发传输的信噪比。

基于上述评估指标，我们进一步使用 SVM 来提高 V2V 通信的性能。SVM 是一种典型的受监督的 ML 算法，培训数据由超过 512 个 HPPP 快照生成。在每个快照中，至少有 10 个 VUE TX 随机分布在网络中。每个 VUE TX 及其目标 VUE RX 都会形成 V2V 链接。网络动态更改。因此，VUEs 位于不同位置时有不同快照，这可能会导致参数的变化，如路径损耗、功率、AoA 和 AoD 的方位角等。这些值可以被收集来用于生成 ML 训练的数据样本。

### 4.迭代1v1 SVM 分类器
#### A. V2V 通信的 ML 培训样本

对于每一个 V2V 链路，VUE 需要从 C 中的 $N_C$ 候选向量中选取一个模拟波束。所以，我们提出一个1v1 SVM 分类器用来波束选择。每一个用来ML训练的数据样本都是基于 $L$ 传播路径。因此，会有 $2+4L$ 个随机真值作为样本元素，其中包括发送端功率、路径损耗、$2L$ 个AoA和AoD的方位角、$2L$ 个复杂增益的实部和虚部。由于样本中不同的元素在不同的取值范围内被选取，因此对数据集进行了归一化预处理。训练数据中的每一个样本都是一个 $2+4L$ 的向量 $\mathbf{x}_{j}, j \in\{1,2, \ldots, J\}$ ，其中的 $J$ 是样本数。每一个数据样本都映射向它自己的最优模拟波束 $\mathbf{c}^{i \*}$, $i\* \in\{1,2, \ldots, N_\mathcal{C}\}$，即如果 $\mathbf{c}^{i \*}$ 被选择了，那么 $\mathrm{SNR}_{\mathrm{V}, k}$ 可以达到一个最大值。因此，将样本分类为成 $N_{\mathcal{C}}$ 个类进行 ML 训练。例如，第 $j$ 个样本是 $\mathbf{x}_{j}$ ，在 $C$ 中被归类为一种模拟波束。 一旦 V2V 链路发生变化，本文提出的 SVM 分类器可以预测模拟波束，在任意两个不同的训练样本之间生成一个分离超平面。此外，由于数据集不平衡，属于某一种样本的数量可能会比其他样本少得多，这给最终结果带来很大的偏差，导致预测不准确。因此，SVM 分类器应该以 “1v1” 的方式进行迭代训练。

> **L propagation paths:** ?
> **$N_{\mathcal{C}}$:** ?  



#### B. 用于 ML 培训的迭代 SMO 算法

1v1 SVM分类器基于 $\mathcal{C}$ 的子集 $\mathbf{U}$，该子集只包含两种模拟波束。每次分类后，从C中提取一个新的候选向量来替换这两种向量中的一种。然后，我们根据更新后的 $\mathbf{U}$ 来继续训练。SMO 算法用来迭代一直到 $N_{\mathcal{C}}-1$ 个候选向量被选中，具体情况如下：

假设在一次迭代中，子集 $\mathbf{U}=\left\{\mathbf{c}_{\mathrm{V}}^{1}, \mathbf{c}_{\mathrm{V}}^{2}\right\} \subset \mathcal{C}$。我们将属于 $\mathbf{c}_{\mathrm{V}}^{1}$ 的训练样本标记为 -1，属于 $\mathbf{c}_{\mathrm{V}}^{2}$ 的训练样本标记为 1。这样便有：
$$
\begin{array}{cc}
\min & \frac{1}{2}\|\mathbf{w}\|^{2}+C \sum\limits_{j=1}^{J} \xi_{j} \\
\text { s.t. } & y_{j}\left[\mathbf{w}^{T} \phi\left(\mathbf{x}_{j}\right)+b\right] \geq 1-\xi_{j} \quad(j \in\{1,2, \ldots, J\}),\quad \xi_{j} \geq 0
\end{array}\tag{13}
$$
这里的 $\mathbf{w}$ 是分离超平面系数的向量，$\phi\left(·\right)$ 为 $\mathbf{x}_{j}$ 到变换后的特征空间的映射，$y_{j}$ 为类标号，$b$ 为超平面公式的常偏置。由于样本噪声的影响，我们使用了松弛变量，它是特征点 $\xi_{j} \geq 0$ 时函数边界的容许值。权值 $C$ 控制支持向量和超平面之间的边界。根据Karush-Kuhn-Tucker条件，得到原问题的拉格朗日函数为：
$$
\mathcal{L}\left(\mathbf{w}, b, \xi_{j}, a_{j}, \beta_{j}\right)=\frac{1}{2}\|\mathbf{w}\|^{2}+C \sum_{j=1}^{J} \xi_{j}
-\sum_{j=1}^{J} a_{j}\left\{y_{j}\left[\mathbf{w}^{T} \mathbf{x}_{j}+b\right]-1+\xi_{j}\right\}-\sum_{j=1}^{J} \beta_{j} \xi_{j}\tag{14}
$$
这里的拉格朗日乘子 $a_{j} \geq 0, \beta_{j} \geq 0, j=1,2, \ldots, J$，这里的核函数 $\phi\left(·\right)$ 是线性核函数。

分别对上式的 $\mathbf{w}$ ，$b$，和 $\xi_{j}$ 求偏导，将结果返回 $\mathcal{L}\left(\mathbf{w}, b, \xi_{j}, a_{j}, \beta_{j}\right)$。那么，**SVM特征的输出函数**为：
$$
\mu_{j}=\sum_{j=1}^{J} a_{j} y_{j} \mathbf{x}_{j}^{T} \mathbf{x}_{j}+b, \quad j=1,2, \ldots, J\tag{15}
$$
考虑（15）和异常值，我们得到如下的 $a_{j}$ ：

+ 当 $a_{j} = 0$ 时，样本属于某一候选码字，**位于支撑平面一侧**，有 $y_{i} \mu_{j} \geq 1$。
+ 当 $0<a_{j}<C$ 时，样本是支持向量，**位于支撑平面上**，有 $y_{i} \mu_{j} = 1$。
+ 当 $a_{j}=C$ 时，支持向量**位于分离的超平面和支持平面之间**，有 $y_{i} \mu_{j} \leq 1$。

$a_{j}$ 同时也满足 $\sum\limits_{j=1}^{J} a_{j} y_{j}=0$ ，当这三个条件未建立时，我们需要同时更新两个 $a_j$ 值。假设我们更新  $a_{j1}$ 和 $a_{j2}$，$j_{1} \neq j_{2}, j_{1}, j_{2} \in{1,2,\dots,J}$ 。我们有：
$$
a_{j_{1}}^{ {new }} y_{1}+a_{j_{2}}^{ {new }} y_{2}=a_{j_{1}}^{ {old }} y_{1}+a_{j_{2}}^{ {old }} y_{2}=\rho\tag{16}
$$
这里的下标“new”和“old”表示更新前后的值，而 $\rho$ 则是常数。定义 $a_{j_{2}}^{\text {new }} \in\left[a_{L}, a_{H}\right]$ ，设置 $\Xi=\{1,2, \ldots, J\} \backslash\left\{j_{1}, j_{2}\right\}$ ，可以得到：

+ 当 $y_{1} y_{2}<0, a_{j_{1}}^{{old }}-a_{j_{2}}^{{old }}=\rho$，那么 $a_{L}=\max (0,-\rho)$，$a_{H}=\min (C, \rho- C)$。
+ 当 $y_{1} y_{2}>0, a_{j_{1}}^{{old }}+a_{j_{2}}^{{old }}=\rho$，那么 $a_{L}=\max (0,\rho- C)$，$a_{H}=\min (C, \rho)$。

从 $\sum\limits_{j=1}^{J} a_{j} y_{j}=0$ 中我们可以知道，$a_{j_{1}} y_{j_{1}}=a_{j_{2}} y_{j_{2}}+\sum\limits_{j \in \Xi} a_{j} y_{j}$。此外，同时在等式两边乘以 $y_{j_{1}}$，有 $a_{j1}=-ta_{j2}+A$，其中的 $t=y_{j1}y_{j2}，A=y_{j_{1}} \sum\limits_{j \in \Xi} a_{j} y_{j}$。

定义 $v_{j_{1}}=\sum_{j \in \Xi} a_{j} y_{j} \mathbf{x}_{j_{1}}^{\mathrm{T}} \mathbf{x}_{j}, v_{j_{2}}=\sum_{j \in \Xi} a_{j} y_{j} \mathbf{x}_{j_{2}}^{\mathrm{T}} \mathbf{x}_{j}$，目标函数改编成：
$$
f\left(a_{j_{1}}, a_{j_{2}}\right)=a_{j_{1}}+a_{j_{2}}-\frac{1}{2} a_{j_{1}}^{2} \mathbf{x}_{j_{1}}^{\mathrm{T}} \mathbf{x}_{j_{1}}-\frac{1}{2} a_{j_{2}}^{2} \mathbf{x}_{j_{2}}^{\mathrm{T}} \mathbf{x}_{j_{2}} \\
-y_{j_{1}} y_{j_{2}} a_{j_{1}} a_{j_{2}} \mathbf{x}_{j_{1}}^{\mathrm{T}} \mathbf{x}_{j_{2}}-y_{j_{1}} a_{j_{1}} v_{j_{1}}-y_{j_{2}} a_{j_{2}} v_{j_{2}}+D
\tag{17}
$$

这里的 $D$ 代表除了 $a_{j1}$ 和 $a_{j2}$ 以外的所有元素。根据 $\frac{\partial f}{\partial a_{j_{2}}}=0$，得到新的 $a_{j2}$ 为：
$$
a_{j_{2}}^{ {new } \prime}=\frac{\left(-y_{j_{1}}+y_{j_{2}}+v_{j_{1}}-v_{j_{2}}-y_{j_{1}} A \mathbf{x}_{j_{1}}^{\mathrm{T}} \mathbf{x}_{j_{2}}+y_{j_{1}} A \mathbf{x}_{j_{1}}^{\mathrm{T}} \mathbf{x}_{j_{1}}\right) y_{j_{2}}}{\mathbf{x}_{j_{1}}^{\mathrm{T}} \mathbf{x}_{j_{1}}+\mathbf{x}_{j_{2}}^{\mathrm{T}} \mathbf{x}_{j_{2}}-2 \mathbf{x}_{j_{1}}^{\mathrm{T}} \mathbf{x}_{j_{2}}}\tag{18}
$$
由于 $j_{1} \neq j_{2}, j_{1}, j_{2} \in\{1,2, \ldots, J\}$，我们可以知道 $\mu_{j_{2}}=\mathbf{w}^{T} \mathbf{x}_{j_{2}}+b$，令 $E_{j_{i}}=\mu_{j_{i}}-y_{j_{i}}, (i=1,2)$，$\zeta=\mathbf{x}_{j_{1}}^{\mathrm{T}} \mathbf{x}_{j_{1}}+\mathbf{x}_{j_{2}}^{\mathrm{T}} \mathbf{x}_{j_{2}}-2 \mathbf{x}_{j_{1}}^{\mathrm{T}} \mathbf{x}_{j_{2}}$。那么，我们有：
$$
a_{j_{2}}^{\text {new } \prime}=a_{j_{2}}^{\text {old }}+\left(y_{j_{2}} / \zeta\right)\left(E_{j_{1}}-E_{j_{2}}\right)\tag{19}
$$
此外，结合 $0<a_{j}<C$ 的约束条件，我们可以得到：
$$
a_{j_{2}}^{ {new }}=\left\{\begin{array}{cc}a_{H} & a_{j_{2}}^{ {new }\prime} < \alpha_{L} \\a_{j_{2}}^{ {new }\prime} & a_{L} \leq a_{j_{2}}^{ {new }\prime} \leq a_{H} \\a_{L} & a_{j_{2}}^{ {new }\prime}>a_{H}\end{array}\right.\tag{20}
$$
根据式（16），我们可以把 $a_{j_{1}}^{\text {new }}$ 更新为：
$$
a_{j_{1}}^{ {new }}=a_{j_{1}}^{o l d}+y_{j_{1}} y_{j_{2}}\left(a_{j_{2}}^{ {old }}-a_{j_{2}}^{ {new }}\right)\tag{21}
$$

> **Karush-Kuhn-Tucker条件:** ?



#### C. 用于 1v1 SVM 培训的迭代 SMO 算法

**Algorithm 1** Iterative SMO training algorithm

--------------
**Initialization:**
​    初始化 $\lambda_{\mathrm{V}}, R, \mathcal{C}, \mathbf{U}=\mathbf{c}^{m}, \mathbf{c}^{n},(m=1, n=2), N_{\mathrm{OBU}}, N_{\mathrm{RV}}, J$
**Loop:**
1. **while**  $k \leftarrow\left\{1,2, \ldots, N_{\mathrm{V}}\right\}$  **do**
2. ​&emsp;根据 $\text{SNR}_{V,k}$ 和 $a_j$ 初始化训练样本 $\mathbf{x}_j$, 标签 $y_j$, $(j \in\{1,2, \ldots, J\})$
3. ​&emsp;&emsp;**for all** $m, n \leq N^{\mathcal{C}},(m \neq n)$ **do**
4. ​&emsp;&emsp;&emsp;&emsp;选择不满足式(15)的三个条件的 $a_{j_1}$
5. ​&emsp;&emsp;&emsp;&emsp;选择拥有 $E_{j_{1}}-E_{j_{2}}$ 最大值的 $a_{j_2}$
6. ​&emsp;&emsp;&emsp;&emsp;混合所有的 $a_{j}, j \in J \backslash\left\{j_{1}, j_{2}\right\}$,计算 $\rho,a_L,a_H,\zeta$
7. ​&emsp;&emsp;&emsp;&emsp;按照式(20)计算 $a_{j_{2}}^{ {new }}$ 的值, 更新 $E_{j_1},E_{j_2}$ 的值
8. ​&emsp;&emsp;&emsp;&emsp;按照式(21)更新 $a_{j_{1}}^{ {new }}$ 的值.
9. ​&emsp;&emsp;&emsp;&emsp;**if** 所有的 $a_j$ 都满足式(15)的三个条件 **then**
10. ​&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;保存所有的 $a_j$ 作为 $\mathbf{c}^{m}, \mathbf{c}^{n}$ 之间的分离超平面 $SP^{m,n}$ 的系数
11. ​&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;更新子集 $\mathbf{U}$ 的 $\mathbf{c}^{m}, \mathbf{c}^{n}$
12. ​&emsp;&emsp;&emsp;&emsp;**end if**
13. ​&emsp;&emsp;**end for**
14. **end while**

**Output:** 在 $\mathbf{c}^{m}, \mathbf{c}^{n}, \left(m, n \leq N^{\mathcal{C}}, m \neq n\right)$ 之间的所有分离超平面 $SP^{m,n}$ 的系数 $a_j,(j \in\{1,2, \ldots, J\})$

--------------

**算法1** 展示了ML训练过程。输出的是所有分离的超平面的系数。根据Osuna 's定理[11]，每次迭代都会减少目标函数(13)，即保证收敛性。

接下来，我们将进一步比较两种传统的算法，即**基于速率的算法**和**信道估计算法**的计算复杂度。基于速率的算法计算所有可能的模拟波束的ASR值。然后，算法选择能够达到最大ASR的模拟波束作为信号传输的最佳模拟波束。由于波束的每一个向量都是一个 $N_{OBU}$ 维的向量，信道矩阵 $\mathbf{H}_\text{V,k}$ 是一个 $N_{OBU}$ 维的方阵。因此，每个 VUE 发送端的计算复杂度是 $\mathcal{O}(N_{OBU}^5)$。如前所述，用来选择的候选波束有 $N_\mathcal{C}$ 个。该计算复杂度为：
$$
\mathcal{O}\left[N_{\mathcal{C}} N_{\mathrm{OBU}}^{5} \frac{N_{\mathrm{V}}\left(1+N_{\mathrm{V}}\right)}{2}\right]=\mathcal{O}\left[\frac{1}{2} N_{\mathcal{C}} N_{\mathrm{OBU}}^{5}\left(N_{\mathrm{V}}^{2}+N_{\mathrm{V}}\right)\right]\tag{22}
$$
然后，信道估计算法根据所有 $L$ 信道路径的CSI选择最佳的模拟波束。每个 VUE 发送端的计算复杂度是 $\mathcal{O}(LN_{OBU}^3)$，该计算复杂度满足：
$$
\mathcal{O}\left[L N_{\mathcal{C}} N_{\mathrm{OBU}}^{3} \frac{N_{\mathrm{V}}\left(1+N_{\mathrm{V}}\right)}{2}\right]=\mathcal{O}\left[\frac{L}{2} N_{\mathcal{C}} N_{\mathrm{OBU}}^{3}\left(N_{\mathrm{V}}^{2}+N_{\mathrm{V}}\right)\right]\tag{23}
$$
最后，本文提出的SVM分类器如果应用于波束选择，必须经过良好的训练，即预先离线进行数据训练（文献17中得知）。因此，数据训练造成的复杂性可以排除。因此，根据前面的分析，可以得到 $\frac{1}{2}\left(N_{\mathcal{C}}\right)^{2}$ 个分离的超平面。每轮迭代之后，超平面的数量都会减半。为了决定测试向量的方向进行的对比包括 $N_{OBU}$ 次乘和加。所以，每一轮的迭代的计算复杂度是 $\mathcal{O}(2N_{OBN})$ 。每一个 VUE 发送端的计算复杂度是 $\mathcal{O}\left[\left(1-\frac{1}{2^{N_{\mathcal{C}}-1}}\right) N_{\mathcal{C}}^{2} N_{\mathrm{OBU}}\right]$。此外，因为平均下来有 $N_{\mathrm{V}}=\left\lfloor\lambda_{\mathrm{V}} \pi R^{2}\right\rfloor$ 个VUE 发送端，所以我们提出的算法的计算复杂度满足：
$$
\begin{array}{l}\mathcal{O}\left[\frac{N_{C}^{2}}{2} N_{\mathrm{OBU}} \frac{N_{\mathrm{V}}\left(1+N_{\mathrm{V}}\right)}{2}\left(1-\frac{1}{2^{N_{\mathcal{C}}-1}}\right)\right] \\=\mathcal{O}\left[N_{\mathcal{C}}^{2} N_{\mathrm{OBU}}\left(N_{\mathrm{V}}^{2}+N_{\mathrm{V}}\right)\left(\frac{1}{4}-\frac{1}{2^{N_{\mathcal{C}}+1}}\right)\right]\end{array}\tag{24}
$$

### 5.仿真讨论

在这一部分，我们通过 Google TensorFlow 对建议的分类器进行训练和评估，其中使用四张 Nvidia Geforce GTX 显卡来加速样本训练。仿真参数见下表。

|    Parameter    |                      Connotation                      |                 Value                  |
| :-------------: | :---------------------------------------------------: | :------------------------------------: |
|    $\lambda$    |            V2V link density<br>V2V链路密度            | $1 \times 10^{-5} \text{V2V link}/m^2$ |
|      $P_V$      |       Maximum VUE TX power<br>VUE 最大发送功率        |                $29dBm$                 |
|       $L$       |       Propagation path number<br/>传播路径数量        |                  $2$                   |
|    $N_{OBU}$    |      Antenna number of OBU<br/>车载单元天线数量       |                  $32$                  |
|       $R$       | Maximum VUE communication radius<br/>VUE 最大通信半径 |                 $20m$                  |
| $N_\mathcal{C}$ | Number of all candidate vectors<br/>所有候选向量数量  |                  $8$                   |

如图2所示，随着 V2V 链路密度的增加，VANET 的 ASR 增加。这是因为更多的 VUE发送端 可以为 VUE接收端 提供更多的通信链路，从而增加低传播损失传输的概率。当 V2V 链路密度持续增加时，ASR 的上升趋势变得缓慢，这意味着几乎所有 VUE接收端 都可以由 VUE发送端 提供。该算法比基于通道估计的现有光束选择算法性能更好，更接近理论最优边界。这是因为 ML 培训可以深入提取系统功能。通道估计算法的性能比建议的算法差，因为它只基于CSI，而CSI只被认为是系统功能的一部分。

<img src="https://i.bmp.ovh/imgs/2021/03/9d512c37b9161277.png" alt="" width="400" align="bottom" />

图三给出了基于速率算法、基于信道估计算法分别与我们的算法的计算复杂度的比较。可以看出，本文提出的算法在计算复杂度上有明显的降低，特别是当VUE链路数量变大时。通过迭代1v1 SVM分类，VUE发送端 可以根据其经过良好训练的分类模型直接选择最佳的模拟波束，而不是尝试所有的模拟波束。因此，该算法的复杂度大大降低。

<img src='https://i.bmp.ovh/imgs/2021/03/b677be393e571c76.png' width="400" align="bottom" />

### 6.总结

本文考虑了基于 ML 的模拟光束毫米波 VANET 中 V2V 通信的选择方法。我们将 V2V 链路建模为 HPPP，以派生 VANETS 的 ASR。此外，还提出了用于选择每个 VUE 的模拟光束的迭代 1v1 SVM 分类器。然后，利用迭代SMO算法获取分离的超平面，使VUE TX快速、准确地选择复杂度极低的模拟光束。仿真结果表明，该算法对理论上边界实现了非常封闭的性能。此外，结果还验证了我们提出的算法不仅得到了比传统信道估计算法更高的 ASR，而且实现了计算复杂性的大幅降低。最后，请注意，我们建议的 ML 分类器仅在 VUE 位置在不同时间更改的动态条件下使用。如果考虑 VUE 的速度，场景的动态性质将变得更加复杂，这显示了我们未来研究工作的有趣和具有挑战性的主题。

> **V2V:**
> V2V(虚拟机到虚拟机的迁移，Virtual to Virtual)，又称虚拟机的克隆。
> V2V迁移是在虚拟机之间移动操作系统和数据，照顾物理机级别的差异和处理不同的虚拟硬件。虚拟机从一个物理机上的虚拟机监视器迁移到另一个物理机的虚拟机监视器，这两个虚拟机监视器的类型可以相同，也可以不同。如VM ware迁移到KVM，KVM迁移到KVM。可以通过多种方式将虚拟机从一个VM Host系统移动到另一个VM Host系统。
>
> **HPPP:** 异构泊松点过程
>
> **VANET:**
> 车载随意移动网络（英语：Vehicular ad-hoc network，缩写为VANET），又称车用移动通信网络，一种移动通信技术，以移动中的车辆及交通设施为节点，利用无线通信技术，来形成移动网络。
>
> **ASR:** 平均传输速率
>
> **VUE TX:** 发送端
>
> **VUE RX:** 接收端
>
> **SVM:**
> 支持向量机（Support Vector Machine, SVM）是一类按监督学习（supervised learning）方式对数据进行二元分类的广义线性分类器（generalized linear classifier），其决策边界是对学习样本求解的最大边距超平面（maximum-margin hyperplane）。
> SVM使用铰链损失函数（hinge loss）计算经验风险（empirical risk）并在求解系统中加入了正则化项以优化结构风险（structural risk），是一个具有稀疏性和稳健性的分类器。SVM可以通过核方法（kernel method）进行非线性分类，是常见的核学习（kernel learning）方法之一。
> SVM被提出于1964年，在二十世纪90年代后得到快速发展并衍生出一系列改进和扩展算法，在人像识别、文本分类等模式识别（pattern recognition）问题中有得到应用。
>
> **SMO:**
> 序列最小优化算法（Sequential minimal optimization, SMO）是一种用于解决[支持向量机]训练过程中所产生优化问题的算法。SMO由微软研究院的约翰·普莱特于1998年发明，被广泛使用于SVM的训练过程中，并在通行的SVM库LIBSVM中得到实现。1998年，SMO算法发表在SVM研究领域内引起了轰动，因为先前可用的SVM训练方法必须使用复杂的方法，并需要昂贵的第三方二次规划工具。而SMO算法较好地避免了这一问题。
>
> **CSI:**
> Channel State Information :信道状态信息.，在无线通信领域，所谓的CSI，就是通信链路的信道属性。它描述了信号在每条传输路径上的衰弱因子，即信道增益矩阵H中每个元素的值，如信号散射（Scattering）,环境衰弱（fading，multipath fading or shadowing fading）,距离衰减（power decay of distance）等信息。CSI可以使通信系统适应当前的信道条件，在多天线系统中为高可靠性高速率的通信提供了保障。
> 一般情况下，接收端评估CSI并将其量化反馈给发送端（在时分双工系统中，需要反向评估）。因此CSI可分为CSIR和CSIT。